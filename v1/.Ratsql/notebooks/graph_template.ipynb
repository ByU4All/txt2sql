{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2ca3b22-46e6-4b6f-bafc-ca79ac054bef",
   "metadata": {},
   "source": [
    "# Langfuse setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d111a2a7-6ab0-4781-8905-fc7826b972b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse import get_client, Langfuse\n",
    "from langfuse.langchain import CallbackHandler\n",
    "\n",
    "LF_SECRET_KEY = \"sk-lf-3d15d46b-46b1-46ba-9747-6e68d73e3125\"\n",
    "LF_PUBLIC_KEY = \"sk-lf-3d15d46b-46b1-46ba-9747-6e68d73e3125\"\n",
    "LF_HOST = \"https://cloud.langfuse.com\"\n",
    "Langfuse(\n",
    "    public_key=LF_PUBLIC_KEY,\n",
    "    secret_key=LF_SECRET_KEY,\n",
    "    host=LF_HOST\n",
    ")\n",
    "# Initialize Langfuse client\n",
    "langfuse = get_client()\n",
    "\n",
    "# Initialize Langfuse CallbackHandler for Langchain (tracing)\n",
    "langfuse_handler = CallbackHandler()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69115693-3415-443a-9437-c15f4748c6ef",
   "metadata": {},
   "source": [
    "# Langchain Ollama setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49b1632e-731a-453a-b8fb-231d89894f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"granite4:350m\",\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4003fc24-7ce7-4dd6-9f59-318667cc8024",
   "metadata": {},
   "source": [
    "# save graph util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a00852cf-0f91-4a28-98d1-c1590af8fe55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_graph_to_file(runnable_graph, output_file_path):\n",
    "    file_path = f\"{output_file_path}.png\"\n",
    "    png_bytes = runnable_graph.get_graph().draw_mermaid_png()\n",
    "    with open(file_path, 'wb') as file:\n",
    "        file.write(png_bytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4570200d-3d18-44b9-9665-0e2b6ff72c51",
   "metadata": {},
   "source": [
    "# Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb64ede0-d7bb-43e6-be60-d1432d75fbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "checkpoint = InMemorySaver()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d56e92f-ba6d-4945-aba9-7250a2aeac41",
   "metadata": {},
   "source": [
    "# EXP ------------->>>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce60285-b6cc-482d-a7a7-41c4dde4e043",
   "metadata": {},
   "source": [
    "## Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc32aadc-2c0e-4655-90a8-51e8523bbac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Node1_prompt = \"\"\"\n",
    "You're a assistance tasked to answer the user question.\n",
    "Use the tools if needed to generate the answer the question.\n",
    "Once you have the answer return the answer to the user and explain why and what tool you used to generate the answer.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33ff5b0-9a1a-4898-9450-03c8edb60e2d",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "51388c66-7d28-454f-bb6d-e89793984f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def addition_tool(arg1, arg2):\n",
    "    \"\"\"\n",
    "    This tool performs addition between two numbers.\n",
    "    Args:\n",
    "        arg1: first number\n",
    "        arg2: second number\n",
    "    \"\"\"\n",
    "    print(\"inside addition tool\")\n",
    "    return arg1 + arg2\n",
    "\n",
    "@tool\n",
    "def subtraction_tool(arg1, arg2):\n",
    "    \"\"\"\n",
    "    This tool performs subtraction between two numbers.\n",
    "    Args:\n",
    "        arg1: first number\n",
    "        arg2: second number\n",
    "    \"\"\"\n",
    "    print(\"inside subtraction tool\")\n",
    "    return arg1 - arg2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3aa4a6-8ab1-4dbf-b8ed-5adb9a572ac4",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3030125b-94bc-4e1a-8401-301605ffabca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "node1_agent = create_agent(\n",
    "    model = llm,\n",
    "    system_prompt = Node1_prompt,\n",
    "    tools = [addition_tool, subtraction_tool],\n",
    "    checkpointer = checkpoint\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7066e4a9-0d1d-4f9e-8800-4bdc9ff48466",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"configurable\": {\"thread_id\": \"1\"},\n",
    "    \"callbacks\":[langfuse_handler]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a3ab10d2-39c2-4cd5-b642-9d75e7206509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside addition tool\n"
     ]
    }
   ],
   "source": [
    "response = node1_agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is 1 + 29\"}]},\n",
    "    config=config,\n",
    "    # context=Context(user_id=\"1\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3da66d-e777-4081-8920-ce4ab662c4a1",
   "metadata": {},
   "source": [
    "## As graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "991d8fad-aa2a-4344-9b7f-585340ecd9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51df1d4-2693-4b5b-8d37-36ca7dd3e24a",
   "metadata": {},
   "source": [
    "### State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d264bd2e-1b75-4060-8f3f-f68196d2393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "\n",
    "class CustomState(MessagesState):\n",
    "    \"\"\"\n",
    "    Custom state for the graph.\n",
    "    \"\"\"\n",
    "    llm_calls : int\n",
    "    resp : int\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a28ec62-5f11-413c-9cdc-dbd9ba21887b",
   "metadata": {},
   "source": [
    "### Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9c112456-86e0-473d-858b-5cd789f41311",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Command\n",
    "\n",
    "def node1(state: CustomState):\n",
    "    node1_agent = create_agent(\n",
    "        model = llm,\n",
    "        system_prompt = Node1_prompt,\n",
    "        tools = [addition_tool, subtraction_tool],\n",
    "        checkpointer = True\n",
    "    )\n",
    "    usr_mess =  state[\"messages\"][-1].content\n",
    "    print(f\"input user message : {usr_mess}\")\n",
    "    response = node1_agent.invoke(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": usr_mess}]},\n",
    "        # config=config,\n",
    "        # context=Context(user_id=\"1\")\n",
    "    )\n",
    "    ans = response[\"messages\"][-1].content\n",
    "    state_to_update = {\n",
    "        \"resp\" : ans,\n",
    "        \"llm_calls\" : 1\n",
    "    }\n",
    "    return Command(\n",
    "        update = state_to_update,\n",
    "        goto=\"__end__\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aef61605-7da0-42b1-8eda-14c74ef77948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7fc0f01a1790>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder = StateGraph(CustomState)\n",
    "\n",
    "graph_builder.add_node(\"node1\", node1)\n",
    "\n",
    "graph_builder.add_edge(START, \"node1\")\n",
    "# graph_builder.add_edge(\"node1\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c361083c-53d5-4edc-8e7b-9480c0a0ef7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "checkpointer = InMemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d3ca69c6-db8e-44df-99d4-238a429e4e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile(checkpointer = checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2baa2374-73ca-4977-b862-b1604e644150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import HumanMessage, AIMessage\n",
    "question = \"What is my name ? \"\n",
    "user_q = HumanMessage(content=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f153f5e3-e86f-4909-850a-dabedc2c12f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input user message : What is my name ? \n"
     ]
    }
   ],
   "source": [
    "final_ans = graph.invoke(\n",
    "    {\n",
    "        \"messages\": [user_q]\n",
    "    },\n",
    "    config = {\n",
    "        \"configurable\": {\n",
    "            \"thread_id\": \"2\",\n",
    "        },\n",
    "        \"callbacks\": [langfuse_handler],\n",
    "        \"metadata\": {\n",
    "            \"langfuse_session_id\": \"ses1\",\n",
    "            \"langfuse_user_id\": \"usr1\",\n",
    "        },\n",
    "    }\n",
    ")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fc58f15e-8676-41ab-8a00-8aef5969a82e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hy my name is luke how are you ? ', additional_kwargs={}, response_metadata={}, id='bfc365c2-00dd-4b8b-9c80-d0a5e169099b'),\n",
       "  HumanMessage(content='What is my name ? ', additional_kwargs={}, response_metadata={}, id='a71598dc-fe76-4295-9f05-07105837c297')],\n",
       " 'llm_calls': 1,\n",
       " 'resp': 'I am a language model trained by IBM Research labs. How can I assist you today?'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28816291-62b1-47b8-b0d5-b5dfb890a48b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "t2ql",
   "language": "python",
   "name": "ratsql"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
